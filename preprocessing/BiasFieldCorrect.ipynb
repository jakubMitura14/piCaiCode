{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ae831f-4c1c-466d-aa20-55fdd9f2fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "from monai.transforms import (\n",
    "    EnsureChannelFirstd,\n",
    "    Orientationd,\n",
    "    AsDiscrete,\n",
    "    AddChanneld,\n",
    "    Spacingd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Resize,\n",
    "    Resized,\n",
    "    RandSpatialCropd,\n",
    "        AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    adaptor,\n",
    "\n",
    "    Invertd,\n",
    ")\n",
    "import torch\n",
    "import torchio as tio\n",
    "\n",
    "# corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "# inputImage = sitk.Cast(image, sitk.sitkFloat32) #required by N4BiasFieldCorrectionImageFilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dffdebe-63b3-47e5-b8d1-de31c734bc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itk_biasField(x):\n",
    "    \"\"\"we need to take the metadata from original file plus modify on the basis of meta_dict\n",
    "    I assume only orientation and spacing may be changed\n",
    "    \"\"\"\n",
    "    print(x['t2w_meta_dict'])\n",
    "    #metaDict = x['t2w_meta_dict']\n",
    "    originalPath=metaDict[]\n",
    "    imageOrig = sitk.ReadImage(path)\n",
    "    imageMonai = sitk.GetImageFromArray(x['t2w'])\n",
    "    SetMetaData\n",
    "    #iterate over metadata of original file and \n",
    "    for key in image.GetMetaDataKeys():\n",
    "        print(\"\\\"{0}\\\":\\\"{1}\\\"\".format(key, image.GetMetaData(key)))\n",
    "    \n",
    "    # print(image.GetSize())\n",
    "    # print(image.GetOrigin())\n",
    "    # print(image.GetSpacing())\n",
    "    # print(image.GetDirection())\n",
    "    \n",
    "    \n",
    "    # smoothed = []\n",
    "    # for channel in x[\"image\"]:\n",
    "    #     smoothed.append(itk.median_image_filter(channel, radius=2))\n",
    "    # x[\"image\"] = np.stack(smoothed)\n",
    "    return x\n",
    "\n",
    "http://insightsoftwareconsortium.github.io/SimpleITK-Notebooks/Python_html/01_Image_Basics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f50dea-0623-487f-be19-5faccf120285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0008|0020': '2019-07-02',\n",
       " '0008|0060': 'MR',\n",
       " '0008|0070': 'SIEMENS',\n",
       " '0008|1090': 'Skyra',\n",
       " '0010|0020': '10000',\n",
       " '0010|0040': 'M',\n",
       " '0010|1010': '073Y',\n",
       " '0012|0062': 'YES',\n",
       " '0020|000d': '1000000',\n",
       " 'ANONYMISATION_SCRIPT': 'PI-CAI anonymisation script v2.0',\n",
       " 'PROSTATE_VOLUME_REPORT': '55',\n",
       " 'PSAD_REPORT': 'nan',\n",
       " 'PSA_REPORT': '7.7',\n",
       " 'spacing': array([0.28125   , 0.28125   , 3.29999998]),\n",
       " 'original_affine': array([[ -0.28125   ,   0.        ,   0.        , 109.22891617],\n",
       "        [  0.        ,  -0.2586998 ,  -1.29471247,  76.61426051],\n",
       "        [  0.        ,  -0.11034481,   3.03541093, -84.29311444],\n",
       "        [  0.        ,   0.        ,   0.        ,   1.        ]]),\n",
       " 'affine': array([[ 2.8125000e-01,  0.0000000e+00,  0.0000000e+00, -7.0489838e+01],\n",
       "        [ 0.0000000e+00,  2.5869980e-01, -1.2947124e+00, -8.8694908e+01],\n",
       "        [ 0.0000000e+00,  1.1034481e-01,  3.0354109e+00, -1.5480345e+02],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
       "       dtype=float32),\n",
       " 'spatial_shape': array([640, 640,  31]),\n",
       " 'original_channel_dim': 'no_channel',\n",
       " 'filename_or_obj': '/home/sliceruser/data/10000/10000_1000000_t2w.mha'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playgroundTrans = Compose(\n",
    "        [\n",
    "            LoadImaged(keys=[\"t2w\", \"label\"]),\n",
    "            EnsureChannelFirstd(keys=[\"t2w\", \"label\"]),\n",
    "            Orientationd(keys=[\"t2w\", \"label\"], axcodes=\"RAS\"),\n",
    "            EnsureTyped(keys=[\"t2w\", \"label\"],dtype=torch.float),\n",
    "            #itk_biasField,\n",
    "            # Spacingd(keys=[\"t2w\", \"label\"], pixdim=(\n",
    "            #     1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "            tio.transforms.EnsureShapeMultiple((32 , 32, 32), include=[\"t2w\", \"label\"]),\n",
    "            #CropForegroundd(keys=[\"t2w\", \"label\"], source_key=\"image\"),\n",
    "\n",
    "            # RandCropByPosNegLabeld(\n",
    "            #     keys=[\"t2w\", \"label\"],\n",
    "            #     label_key=\"label\",\n",
    "            #     spatial_size=(32, 32, 32),\n",
    "            #     pos=1,\n",
    "            #     neg=1,\n",
    "            #     num_samples=4,\n",
    "            #     image_key=\"t2w\",\n",
    "            #     image_threshold=0,\n",
    "            # ),\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# {'0008|0020': '2019-07-02',\n",
    "#  '0008|0060': 'MR',\n",
    "#  '0008|0070': 'SIEMENS',\n",
    "#  '0008|1090': 'Skyra',\n",
    "#  '0010|0020': '10000',\n",
    "#  '0010|0040': 'M',\n",
    "#  '0010|1010': '073Y',\n",
    "#  '0012|0062': 'YES',\n",
    "#  '0020|000d': '1000000',\n",
    "#  'ANONYMISATION_SCRIPT': 'PI-CAI anonymisation script v2.0',\n",
    "#  'PROSTATE_VOLUME_REPORT': '55',\n",
    "#  'PSAD_REPORT': 'nan',\n",
    "#  'PSA_REPORT': '7.7',\n",
    "#  'spacing': array([0.28125   , 0.28125   , 3.29999998]),\n",
    "#  'original_affine': array([[ -0.28125   ,   0.        ,   0.        , 109.22891617],\n",
    "#         [  0.        ,  -0.2586998 ,  -1.29471247,  76.61426051],\n",
    "#         [  0.        ,  -0.11034481,   3.03541093, -84.29311444],\n",
    "#         [  0.        ,   0.        ,   0.        ,   1.        ]]),\n",
    "#  'affine': array([[ 2.8125000e-01,  0.0000000e+00,  0.0000000e+00, -7.0489838e+01],\n",
    "#         [ 0.0000000e+00,  2.5869980e-01, -1.2947124e+00, -8.8694908e+01],\n",
    "#         [ 0.0000000e+00,  1.1034481e-01,  3.0354109e+00, -1.5480345e+02],\n",
    "#         [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]],\n",
    "#        dtype=float32),\n",
    "#  'spatial_shape': array([640, 640,  31]),\n",
    "#  'original_channel_dim': 'no_channel',\n",
    "#  'filename_or_obj': '/home/sliceruser/data/10000/10000_1000000_t2w.mha'}\n",
    "\n",
    "\n",
    "testDict={\"t2w\":\"/home/sliceruser/data/10000/10000_1000000_t2w.mha\", \"label\": \"/home/sliceruser/labels/csPCa_lesion_delineations/human_expert/resampled/10000_1000000.nii.gz\"}    \n",
    "playgroundTrans(testDict)['t2w_meta_dict']    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73b1efb9-7777-48a5-982f-c4d7acc5d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathBaselineImage ='/home/sliceruser/data/10001/10001_1000001_t2w.mha'\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import collections\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "from scipy.stats import iqr\n",
    "\n",
    "# used to remove outlier values - when higher or lowe values will get clipped\n",
    "\n",
    "\n",
    "testDict={\"t2w\":\"/home/sliceruser/data/10000/10000_1000000_t2w.mha\", \"label\": \"/home/sliceruser/labels/csPCa_lesion_delineations/human_expert/resampled/10000_1000000.nii.gz\"}    \n",
    "pathh=testDict['t2w']\n",
    "\n",
    "def removeOutliersBiasFieldCorrect(path,numberOfStandardDeviations = 4):\n",
    "    \"\"\"\n",
    "    all taken from https://github.com/NIH-MIP/Radiology_Image_Preprocessing_for_Deep_Learning/blob/main/Codes/Main_Preprocessing.py\n",
    "    my modification that instead of histogram usage for outliers I use the standard deviations\n",
    "    path - path to file to be processed\n",
    "    numberOfStandardDeviations- osed to define outliers\n",
    "\n",
    "    \"\"\"\n",
    "    image1 = sitk.ReadImage(pathh)\n",
    "    data = sitk.GetArrayFromImage(image1)\n",
    "    # shift the data up so that all intensity values turn positive\n",
    "    stdd = np.std(data)*5\n",
    "    median = np.median(data)\n",
    "    data = np.clip(data, median-numberOfStandardDeviations*stdd, median+numberOfStandardDeviations*stdd)\n",
    "    data -= np.min(data)\n",
    "    #TO normalize an image by mapping its [Min,Max] into the interval [0,255]\n",
    "    N=255\n",
    "    data=N*(data+600)/2000\n",
    "\n",
    "    #recreating image keeping relevant metadata\n",
    "    image = sitk.GetImageFromArray(data)\n",
    "    image.SetSpacing(image1.GetSpacing())\n",
    "    image.SetOrigin(image1.GetOrigin())\n",
    "    image.SetDirection(image1.GetDirection())\n",
    "    #bias field normalization\n",
    "    maskImage = sitk.OtsuThreshold(image, 0, 1, 200)\n",
    "    inputImage = sitk.Cast(image, sitk.sitkFloat32)\n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    # numberFittingLevels = 4\n",
    "    imageB = corrector.Execute(inputImage, maskImage)\n",
    "    imageB.SetSpacing(image.GetSpacing())\n",
    "    imageB.SetOrigin(image.GetOrigin())\n",
    "    imageB.SetDirection(image.GetDirection())\n",
    "    return imageB\n",
    "\n",
    "\n",
    "# imageOrig = sitk.ReadImage(pathh)\n",
    "# corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "# inputImage = sitk.Cast(image, sitk.sitkFloat32) #required by N4BiasFieldCorrectionImageFilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24e6924e-a251-4516-89b6-feecb2c2f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standarization by https://github.com/NIH-MIP/Radiology_Image_Preprocessing_for_Deep_Learning/blob/main/Codes/Main_Preprocessing.py\n",
    "imagee=removeOutliersBiasFieldCorrect(pathh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "70dfacbc-6bbe-48a8-967e-6d7b2e1e2e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SimpleITK.SimpleITK.Image; proxy of <Swig Object of type 'std::vector< itk::simple::Image >::value_type *' at 0x7ff852a73a50> >"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca5fd66e-c5ad-48e6-844f-05cce605509c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097.5063913517986"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663cbcee-3dc7-4822-b687-65e10c0eb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.clip(data, 0, Bin)\n",
    "image = sitk.GetImageFromArray(data)\n",
    "image.SetSpacing(image1.GetSpacing())\n",
    "image.SetOrigin(image1.GetOrigin())\n",
    "image.SetDirection(image1.GetDirection())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029c4bf0-7d4c-41d1-8995-60190cf44cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
