{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from zipfile import ZipFile\n",
    "from zipfile import BadZipFile\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import Standardize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## managment of files \n",
    "managment of files is done via managePicaiFiles.sh - create directories download and unpack files saves basic metadata and do simple metadata preprocessing\n",
    "sh managePicaiFiles.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standarization\n",
    "primary preprocessing - removing ouliers, put values between 0 and 255 bias field correction Nyul standarization binarizing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Standardize\n",
    "df = pd.read_csv('/home/sliceruser/data/metadata/processedMetaData.csv')\n",
    "numRows=5\n",
    "Standardize.iterateAndchangeLabelToOnes(numRows,df)\n",
    "for keyWord in ['t2w','adc', 'cor','hbv','sag'  ]:\n",
    "    Standardize.iterateAndStandardize(keyWord,numRows,df)\n",
    "\n",
    "df.to_csv('/home/sliceruser/data/metadata/processedMetaData.csv') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all of the spacings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# if using a Jupyter notebook, includue:\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacingDict={}\n",
    "for keyWord in ['t2w','adc', 'cor','hbv','sag'  ]: \n",
    "    for addedKey in ['_spac_x','_spac_y','_spac_z']:   \n",
    "\n",
    "        colName = keyWord+addedKey\n",
    "        minn=np.min(df[colName].to_numpy())                \n",
    "        maxx=np.max(df[colName].to_numpy())\n",
    "        spacingDict[colName]=(minn,maxx)\n",
    "\n",
    "spacingDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/sliceruser/data/orig/10000/10000_1000000_t2w.mha'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KevinSR import mask_interpolation, SOUP_GAN\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import ndimage, interpolate\n",
    "from scipy.ndimage import zoom\n",
    "from KevinSR import SOUP_GAN\n",
    "import monai\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "path = df['t2w'].to_numpy()[0]\n",
    "img = sitk.ReadImage(path)\n",
    "reoriented = sitk.DICOMOrient(img, 'RAS')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Example of thick-to-thin type of preprocessing\n",
    "pre_slices = 27\n",
    "post_slices = 135\n",
    "\n",
    "\n",
    "# thicks_ori = load_data(DIR_dicom)\n",
    "# Z_FAC = post_slices/pre_slices # Sampling factor in Z direction\n",
    "\n",
    "# thicks_ori = rescale_img(thicks_ori, max_val= 10000)\n",
    "\n",
    "# thins = zoom(thicks_ori, (1,1,Z_FAC))\n",
    "# thins_raw = zoom(thicks_ori, (1,1,Z_FAC),order=0)\n",
    "\n",
    "# # Call the SR interpolation tool from KevinSR\n",
    "# thins_gen = SOUP_GAN(thicks_ori, Z_FAC, 0)\n",
    "\n",
    "# # Plot the original thick slices, thin slices by TCI and SR generated slices. \n",
    "# plot_scans(thins_raw, thins, thins_gen, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for keyWord in ['t2w','adc', 'cor','hbv','sag'  ]: \n",
    "#     for addedKey in ['_sizz_x','_sizz_y','_sizz_z','_spac_x'\n",
    "#                         ,'_spac_y','_spac_z'\n",
    "#                         ,'_orig_x','_orig_x','_orig_x']:  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
