{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21cfb3ce-620a-48de-a1bf-251aab2efb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import SimpleITK as sitk\n",
    "from os import listdir\n",
    "from scipy.interpolate import interp1d\n",
    "import time\n",
    "import pandas as pd\n",
    "from os.path import isdir,join,exists,split,dirname,basename\n",
    "import numpy as np\n",
    "\n",
    "def tic():\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "\n",
    "def toc():\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        print\n",
    "        \"Elapsed time is \" + str(time.time() - startTime_for_tictoc) + \" seconds.\"\n",
    "    else:\n",
    "        print\n",
    "        \"Toc: start time not set\"\n",
    "\n",
    "\n",
    "def getCdf(hist):\n",
    "    \"\"\"\n",
    "        Given a histogram, it returns the cumulative distribution function.\n",
    "    \"\"\"\n",
    "    aux = np.cumsum(hist)\n",
    "    aux = aux / aux[-1] * 100\n",
    "    return aux\n",
    "\n",
    "\n",
    "def getPercentile(cdf, bins, perc):\n",
    "    \"\"\"\n",
    "        Given a cumulative distribution function obtained from a histogram,\n",
    "        (where 'bins' are the x values of the histogram and 'cdf' is the\n",
    "        cumulative distribution function of the original histogram), it returns\n",
    "        the x center value for the bin index corresponding to the given percentile,\n",
    "        and the bin index itself.\n",
    "\n",
    "        Example:\n",
    "\n",
    "            import numpy as np\n",
    "            hist = np.array([204., 1651., 2405., 1972., 872., 1455.])\n",
    "            bins = np.array([0., 1., 2., 3., 4., 5., 6.])\n",
    "\n",
    "            cumHist = getCdf(hist)\n",
    "            print cumHist\n",
    "            val, bin = getPercentile(cumHist, bins, 50)\n",
    "\n",
    "            print \"Val = \" + str(val)\n",
    "            print \"Bin = \" + str(bin)\n",
    "\n",
    "    \"\"\"\n",
    "    b = len(bins[cdf <= perc])\n",
    "    return bins[b] + ((bins[1] - bins[0]) / 2)\n",
    "\n",
    "\n",
    "\n",
    "def getLandmarks(image, mask=None, showLandmarks=False,nbins=1024, pLow=1, pHigh=99,numPoints=10):\n",
    "        \"\"\"\n",
    "            This Private function obtain the landmarks for a given image and returns them\n",
    "            in a list like:\n",
    "                [lm_pLow, lm_perc1, lm_perc2, ... lm_perc_(numPoints-1), lm_pHigh] (lm means landmark)\n",
    "\n",
    "            :param image    SimpleITK image for which the landmarks are computed.\n",
    "            :param mask     [OPTIONAL] SimpleITK image containing a mask. If provided, the histogram will be computed\n",
    "                                    taking into account only the voxels where mask > 0.\n",
    "            :param showLandmarks    Plot the landmarks using matplotlib on top of the histogram.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        data = sitk.GetArrayFromImage(image)\n",
    "        if mask is None:\n",
    "            # Calculate useful statistics\n",
    "            stats = sitk.StatisticsImageFilter()\n",
    "            stats.Execute(image)\n",
    "            mean =stats.GetMean()\n",
    "\n",
    "            # Compute the image histogram\n",
    "            histo, bins = np.histogram(data.flatten(), nbins)\n",
    "\n",
    "            # Calculate the cumulative distribution function of the original histogram\n",
    "            cdfOriginal = getCdf(histo)\n",
    "\n",
    "            # Truncate the histogram (put 0 to those values whose intensity is less than the mean)\n",
    "            # so that only the foreground values are considered for the landmark learning process\n",
    "            histo[bins[:-1] < mean] = 0.0\n",
    "        # else:\n",
    "        #     # Calculate useful statistics\n",
    "        #     dataMask = sitk.GetArrayFromImage(mask)\n",
    "        #\n",
    "        #     # Compute the image histogram\n",
    "        #     histo, bins = np.histogram(data[dataMask > 0].flatten(), nbins, normed=True)\n",
    "        #\n",
    "        #     # Calculate the cumulative distribution function of the original histogram\n",
    "        #     cdfOriginal = getCdf(histo)\n",
    "\n",
    "        # Calculate the cumulative distribution function of the truncated histogram, where outliers are removed\n",
    "        cdfTruncated = getCdf(histo)\n",
    "\n",
    "        # Generate the percentile landmarks for  m_i\n",
    "        perc = [x for x in range(0, 100, 100 // numPoints)]\n",
    "        # Remove the first landmark that will always correspond to 0\n",
    "        perc = perc[1:]\n",
    "\n",
    "        # Generate the landmarks. Note that those corresponding to pLow and pHigh (at the beginning and the\n",
    "        # end of the list of landmarks) are generated from the cdfOriginal, while the ones\n",
    "        # corresponding to the percentiles are generated from cdfTruncated, meaning that only foreground intensities\n",
    "        # are considered.\n",
    "\n",
    "        landmarks = [getPercentile(cdfOriginal, bins[:-1], pLow)] + [getPercentile(cdfTruncated, bins[:-1], x) for x in perc] + [getPercentile(cdfOriginal, bins[:-1], pHigh)]\n",
    "        # landmarks_org =  [getPercentile(cdfOriginal, bins[:-1], x) for x in [pLow]+perc+[pHigh]]\n",
    "        return landmarks\n",
    "\n",
    "def  landmarksSanityCheck(landmarks):\n",
    "        Flag=True\n",
    "        if not (np.unique(landmarks).size == len(landmarks)):\n",
    "            for i in range(1, len(landmarks) - 1):\n",
    "                if landmarks[i] == landmarks[i + 1]:\n",
    "                    landmarks[i] = (landmarks[i - 1] + landmarks[i + 1]) / 2.0\n",
    "\n",
    "                print( \"WARNING: Fixing duplicate landmark.\")\n",
    "\n",
    "            if not (np.unique(landmarks).size == len(landmarks)):\n",
    "                raise Exception('ERROR NyulNormalizer landmarks sanity check : One of the landmarks is duplicate. You can try increasing the number of bins in the histogram \\\n",
    "                (NyulNormalizer.nbins) to avoid this behaviour. Landmarks are: ' + str(landmarks))\n",
    "\n",
    "        elif not (sorted(landmarks) == list(landmarks)):\n",
    "            Flag=False\n",
    "\n",
    "        return Flag\n",
    "            # raise Exception(\n",
    "            #     'ERROR NyulNormalizer landmarks sanity check: Landmarks in the list are not sorted, while they should be. Landmarks are: ' + str(\n",
    "            #         landmarks))\n",
    "def train(image_list,dir1,dir2,pLow=1, pHigh=99, sMin=1, sMax=99, numPoints=10,\n",
    "              showLandmarks=False,nbins=1024):\n",
    "\n",
    "        # Percentiles used to trunk the tails of the histogram\n",
    "        if pLow > 10:\n",
    "            raise (\"NyulNormalizer Error: pLow may be bigger than the first lm_pXX landmark.\")\n",
    "        if pHigh < 90:\n",
    "            raise (\"NyulNormalizer Error: pHigh may be bigger than the first lm_pXX landmark.\")\n",
    "\n",
    "        allMappedLandmarks = []\n",
    "\n",
    "        for image in image_list:\n",
    "\n",
    "            img = sitk.ReadImage(image)\n",
    "\n",
    "            landmarks = getLandmarks(img, showLandmarks=showLandmarks,nbins=nbins,pHigh=pHigh,pLow=pLow,numPoints=numPoints)\n",
    "                                    # Check the obtained landmarks ...\n",
    "            if landmarksSanityCheck(landmarks):\n",
    "                # Construct the linear mapping function\n",
    "                mapping = interp1d([landmarks[0], landmarks[-1]], [sMin, sMax], fill_value=(0,100))\n",
    "                # Map the landmarks to the standard scale\n",
    "                mappedLandmarks = mapping(landmarks)\n",
    "                # Add the mapped landmarks to the working set\n",
    "                allMappedLandmarks.append(mappedLandmarks)\n",
    "\n",
    "\n",
    "        meanLandmarks = np.array(allMappedLandmarks).mean(axis=0)\n",
    "            # Check the obtained landmarks ...\n",
    "        landmarksSanityCheck(meanLandmarks)\n",
    "        trainedModel = {\n",
    "                'pLow': pLow,\n",
    "                'pHigh': pHigh,\n",
    "                'sMin': sMin,\n",
    "                'sMax': sMax,\n",
    "                'numPoints': numPoints,\n",
    "                'meanLandmarks': meanLandmarks}\n",
    "\n",
    "        np.savez(dir2, trainedModel=[trainedModel])\n",
    "        return True\n",
    "def shif_by_negative_value(array):\n",
    "    array-=np.min(array)\n",
    "    return array\n",
    "def transform(image,meanLandmarks,mask=None):\n",
    "    # Get the raw data of the image\n",
    "    data = sitk.GetArrayFromImage(image)\n",
    "    # data = standardize(data, type='image')\n",
    "    # Calculate useful statistics\n",
    "    stats = sitk.StatisticsImageFilter()\n",
    "    stats.Execute(image)\n",
    "\n",
    "\n",
    "    # Get the landmarks for the current image\n",
    "    landmarks = getLandmarks(image, mask=mask, nbins=1024,pHigh=99,pLow=1,numPoints=10)\n",
    "    landmarks = np.array(landmarks)\n",
    "    # print(landmarks)\n",
    "    # Check the obtained landmarks ...\n",
    "    landmarksSanityCheck(landmarks)\n",
    "\n",
    "    # Recover the standard scale landmarks\n",
    "    standardScale = meanLandmarks\n",
    "\n",
    "\n",
    "    # Construct the piecewise linear interpolator to map the landmarks to the standard scale\n",
    "    mapping = interp1d(landmarks, standardScale, fill_value=\"extrapolate\")\n",
    "\n",
    "    # Map the input image to the standard space using the piecewise linear function\n",
    "\n",
    "    flatData = data.ravel()\n",
    "    tic()\n",
    "    mappedData = mapping(flatData)\n",
    "    mappedlandmarks = mapping(landmarks)\n",
    "    histo,bins=np.histogram(mappedData, 1024)\n",
    "    toc()\n",
    "    mappedData = mappedData.reshape(data.shape)\n",
    "\n",
    "    output = sitk.GetImageFromArray(shif_by_negative_value(mappedData.astype(int)))\n",
    "    output.SetSpacing(image.GetSpacing())\n",
    "    output.SetOrigin(image.GetOrigin())\n",
    "    output.SetDirection(image.GetDirection())\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a1d59-211d-4222-94f1-4cdb585a451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainForStandarization(imageTypeStr)\n",
    "\"\"\"\n",
    "imageTypeStr -String telling what type of image it is - like t2w, adc... \n",
    "\"\"\"\n",
    "\n",
    "    train(train_patients, dir1=join(\"/home/sliceruser/preprocess/Bias_field_corrected\",t2w),\n",
    "                                   dir2=join(args.target_folder,'trained_model'+args.image_type+'.npz'))\n",
    "    Model_Path = join(args.target_folder,'trained_model'+args.image_type+'.npz')\n",
    "    f = np.load(Model_Path, allow_pickle=True)\n",
    "    Model = f['trainedModel'].all()\n",
    "    meanLandmarks = Model['meanLandmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9730f80-043f-4864-9eec-f726d32ef6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvPath='/home/sliceruser/labels/clinical_information/marksheet.csv'\n",
    "df = pd.read_csv('/home/sliceruser/labels/processedMetaData.csv')\n",
    "\n",
    "train_patients=df['t2w'].dropna().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d802e53-08a7-4c12-a3e0-288adf6a74eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seriesString=\"t2w\"\n",
    "trainedModel=join('/home/sliceruser/preprocess','trained_model'+seriesString+'.npz')\n",
    "train(train_patients, dir1=join(\"/home/sliceruser/preprocess/Bias_field_corrected\",seriesString),\n",
    "                                   dir2=trainedModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3be3c13a-cb91-497e-bddf-cf75a5202ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel=join('/home/sliceruser/preprocess','trained_model'+seriesString+'.npz')\n",
    "f = np.load(trainedModel, allow_pickle=True)\n",
    "Model = f['trainedModel'].all()\n",
    "meanLandmarks = Model['meanLandmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98718c32-b813-4dbd-b773-204a276f035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when model is trained and we have appropriate landmarks we can use them by \n",
    "testDict={\"t2w\":\"/home/sliceruser/data/10000/10000_1000000_t2w.mha\", \"label\": \"/home/sliceruser/labels/csPCa_lesion_delineations/human_expert/resampled/10000_1000000.nii.gz\"}    \n",
    "pathh=testDict['t2w']\n",
    "image_B = sitk.ReadImage(pathh)\n",
    "\n",
    "image= transform(image_B,meanLandmarks=meanLandmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d7d7409-ba79-4fa4-9e80-b0db23cf3d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SimpleITK.SimpleITK.Image; proxy of <Swig Object of type 'std::vector< itk::simple::Image >::value_type *' at 0x7fb607396120> >"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c868ad3-b35d-44f2-a33e-7c22bb26354d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcmPath='/home/sliceruser/data/10000/10000_1000000_t2wB.mha'\n",
    "writer = sitk.ImageFileWriter()\n",
    "writer.KeepOriginalImageUIDOn()\n",
    "writer.SetFileName(dcmPath)\n",
    "writer.Execute(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48b6503d-4548-46f9-8e5f-606f36bde985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.9198214989417033,\n",
       " 0.3923371128056057,\n",
       " 0.0,\n",
       " -0.3923371128056057,\n",
       " 0.9198214989417033)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_C = sitk.ReadImage(dcmPath)\n",
    "image_C.GetDirection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c346e177-962b-45cc-bc3e-c2bade9a0882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
