{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "from zipfile import ZipFile\n",
    "from zipfile import BadZipFile\n",
    "import dask.dataframe as dd\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "import functools\n",
    "from functools import partial\n",
    "import Standardize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## managment of files \n",
    "managment of files is done via managePicaiFiles.sh - create directories download and unpack files saves basic metadata and do simple metadata preprocessing\n",
    "sh managePicaiFiles.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standarization\n",
    "primary preprocessing - removing ouliers, put values between 0 and 255 bias field correction Nyul standarization binarizing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /home/sliceruser/data/orig/10000/10000_1000000...\n",
       "1       /home/sliceruser/data/orig/10001/10001_1000001...\n",
       "2       /home/sliceruser/data/orig/10002/10002_1000002...\n",
       "3       /home/sliceruser/data/orig/10003/10003_1000003...\n",
       "4       /home/sliceruser/data/orig/10004/10004_1000004...\n",
       "                              ...                        \n",
       "1495    /home/sliceruser/data/orig/11471/11471_1001495...\n",
       "1496    /home/sliceruser/data/orig/11472/11472_1001496...\n",
       "1497    /home/sliceruser/data/orig/11473/11473_1001497...\n",
       "1498    /home/sliceruser/data/orig/11474/11474_1001498...\n",
       "1499    /home/sliceruser/data/orig/11475/11475_1001499...\n",
       "Name: sag, Length: 1500, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/sliceruser/data/metadata/processedMetaData.csv')\n",
    "df['sag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Standardize\n",
    "\n",
    "df = pd.read_csv('/home/sliceruser/data/metadata/processedMetaData.csv')\n",
    "numRows=10\n",
    "Standardize.iterateAndchangeLabelToOnes(numRows,df)\n",
    "for keyWord in ['t2w','adc', 'cor','hbv','sag'  ]:\n",
    "    Standardize.iterateAndStandardize(keyWord,numRows,df)\n",
    "\n",
    "df.to_csv('/home/sliceruser/data/metadata/processedMetaData.csv') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Unires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frst we need to save files as nifti- we will keep the same folder structure just alternate file type\n",
    "def saveAsNifti(path):\n",
    "    image=sitk.ReadImage(path)\n",
    "    newPath = path.replace(\".mha\",\".nii.gz\")\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    writer.KeepOriginalImageUIDOn()\n",
    "    writer.SetFileName(newPath)\n",
    "    writer.Execute(image)\n",
    "    return newPath\n",
    "\n",
    "for keyWord in ['t2w','adc', 'cor','hbv','sag','reSampledPath']:\n",
    "    train_patientsPaths=df[keyWord].dropna().astype('str').to_numpy()\n",
    "    train_patientsPaths=list(filter(lambda path: len(path)>2 ,train_patientsPaths))\n",
    "    with mp.Pool(processes = mp.cpu_count()) as pool:\n",
    "        pool.map(saveAsNifti,train_patientsPaths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:nitorch uses its non-compiled backend (TS). Some algorithms may be slow.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "262.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unires.struct import settings as s\n",
    "from unires.run import preproc\n",
    "\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/home/sliceruser/data/metadata/processedMetaData.csv')\n",
    "numb= 19\n",
    "\n",
    "pathT2w=df['t2w'].to_numpy()[numb]\n",
    "pathCor=df['cor'].to_numpy()[numb]\n",
    "pathSag=df['sag'].to_numpy()[numb]\n",
    "pathHbv=df['hbv'].to_numpy()[numb]\n",
    "pathAdc=df['adc'].to_numpy()[numb]\n",
    "pathLabel=df['reSampledPath'].to_numpy()[numb]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def saveAsNifti(path):\n",
    "    image=sitk.ReadImage(path)\n",
    "    newPath = path.replace(\".mha\",\".nii.gz\")\n",
    "    writer = sitk.ImageFileWriter()\n",
    "    writer.KeepOriginalImageUIDOn()\n",
    "    writer.SetFileName(newPath)\n",
    "    writer.Execute(image)\n",
    "    return newPath\n",
    "pathT2wNew = saveAsNifti(pathT2w)\n",
    "pathCorNew = saveAsNifti(pathCor)\n",
    "pathSagNew=saveAsNifti(pathSag)\n",
    "pathHbvNew=saveAsNifti(pathHbv)\n",
    "pathAdcNew=saveAsNifti(pathAdc)\n",
    "pathLabelNew=saveAsNifti(pathLabel)\n",
    "\n",
    "\n",
    "df['isAnythingInAnnotated'].to_numpy()[numb]\n",
    "\n",
    "#image1=sitk.ReadImage(pathT2w)\n",
    "# pathT2w.replace(\".mha\",\".nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sliceruser/data/orig/10019/10019_1000019_t2w.nii.gz\n",
      "/home/sliceruser/data/orig/10019/10019_1000019_cor.nii.gz\n",
      "/home/sliceruser/data/orig/10019/10019_1000019_sag.nii.gz\n"
     ]
    }
   ],
   "source": [
    "print(pathT2wNew)\n",
    "print(pathCorNew)\n",
    "print(pathSagNew)\n",
    "sett=s()\n",
    "sett.device='cpu' #TODO() remove\n",
    "#sett.do_atlas_align='false'\n",
    "sett.do_atlas_align=False\n",
    "#sett.cgs_max_iter=3#TODO() remove\n",
    "sett.max_iter=110#TODO() remove\n",
    "sett.dir_out = '/home/sliceruser/data/Unires'\n",
    "sett.label= pathLabelNew\n",
    "\n",
    "\n",
    "# in command line\n",
    "# unires /home/sliceruser/data/orig/10000/10000_1000000_t2w.nii.gz /home/sliceruser/data/orig/10000/10000_1000000_cor.nii.gz /home/sliceruser/data/orig/10000/10000_1000000_sag.nii.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _   _       _ ____           \n",
      " | | | |_ __ (_)  _ \\ ___  ___ \n",
      " | | | | '_ \\| | |_) / _ \\/ __|\n",
      " | |_| | | | | |  _ <  __/\\__ \\\n",
      "  \\___/|_| |_|_|_| \\_\\___||___/\n",
      "\n",
      "CPU\n",
      "\n",
      "Input\n",
      "c=0, n=0 | fname=/home/sliceruser/data/orig/10019/10019_1000019_t2w.nii.gz\n",
      "c=1, n=0 | fname=/home/sliceruser/data/orig/10019/10019_1000019_cor.nii.gz\n",
      "c=2, n=0 | fname=/home/sliceruser/data/orig/10019/10019_1000019_sag.nii.gz\n",
      "c=3, n=0 | fname=/home/sliceruser/data/orig/10019/10019_1000019_hbv.nii.gz\n",
      "c=4, n=0 | fname=/home/sliceruser/data/orig/10019/10019_1000019_adc.nii.gz\n",
      "\n",
      "Estimating model hyper-parameters... completed in 0.53629 seconds:\n",
      "c=0 | tau= 0.0004649 | sd=     46.38 | mu=       251 | ct=False \n",
      "c=1 | tau= 0.0008579 | sd=     34.14 | mu=     260.4 | ct=False \n",
      "c=2 | tau= 0.0004211 | sd=     48.73 | mu=     263.8 | ct=False \n",
      "c=3 | tau=    0.1346 | sd=     2.725 | mu=     13.35 | ct=False \n",
      "c=4 | tau= 2.002e-05 | sd=     223.5 | mu=      1059 | ct=False \n",
      "\n",
      "Performing multi-channel (N=5) alignment...completed in 67.09729 seconds.\n",
      "\n",
      "Mean space | dim=(311, 263, 223), vx=(1.0, 1.0, 1.0)\n",
      "\n",
      "ADMM step-size=0.3300\n",
      "\n",
      "Starting super-resolution (update_rigid=True, update_scaling=True) \n",
      " | C=5 | N=5 | device=cpu | max_iter=110 | tol=0.0001 | sched_num=3\n",
      "  0 - Convergence (290.3 s)  | nlyx =  2.669e+07, nlxy =  1.051e+07, nly =  1.618e+07, gain =        inf\n"
     ]
    }
   ],
   "source": [
    "res = preproc([pathT2wNew, pathCorNew,pathSagNew,pathHbvNew,pathAdcNew ],sett=sett)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a='/home/sliceruser/data/Unires/ur_10000_1000000_cor.nii.gz'\n",
    "b='/home/sliceruser/data/Unires/ur_10000_1000000_sag.nii.gz'\n",
    "c='/home/sliceruser/data/Unires/ur_10000_1000000_t2w.nii.gz'\n",
    "image=sitk.ReadImage(c)\n",
    "image.GetSpacing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(203, 251, 252)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all of the spacings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# if using a Jupyter notebook, includue:\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t2w_spac_x': (0.234375, 0.78125),\n",
       " 't2w_spac_y': (0.234375, 0.78125),\n",
       " 't2w_spac_z': (2.200000060372773, 5.000000066297424),\n",
       " 'adc_spac_x': (0.234375, 0.78125),\n",
       " 'adc_spac_y': (0.234375, 0.78125),\n",
       " 'adc_spac_z': (2.200000060372773, 5.000000066297424),\n",
       " 'cor_spac_x': (0.234375, 0.78125),\n",
       " 'cor_spac_y': (0.234375, 0.78125),\n",
       " 'cor_spac_z': (2.200000060372773, 5.000000066297424),\n",
       " 'hbv_spac_x': (0.234375, 0.78125),\n",
       " 'hbv_spac_y': (0.234375, 0.78125),\n",
       " 'hbv_spac_z': (2.200000060372773, 5.000000066297424),\n",
       " 'sag_spac_x': (0.234375, 0.78125),\n",
       " 'sag_spac_y': (0.234375, 0.78125),\n",
       " 'sag_spac_z': (2.200000060372773, 5.000000066297424)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacingDict={}\n",
    "for keyWord in ['t2w','adc', 'cor','hbv','sag'  ]: \n",
    "    for addedKey in ['_spac_x','_spac_y','_spac_z']:   \n",
    "\n",
    "        colName = keyWord+addedKey\n",
    "        minn=np.min(df[colName].to_numpy())                \n",
    "        maxx=np.max(df[colName].to_numpy())\n",
    "        spacingDict[colName]=(minn,maxx)\n",
    "\n",
    "spacingDict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.200000060372773, 5.000000066297424)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minXSpac = spacingDict['t2w_spac_x'][0]\n",
    "minYSpac = spacingDict['t2w_spac_y'][0]\n",
    "minZSpac = spacingDict['t2w_spac_z'][0]\n",
    "spacingDict['t2w_spac_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from KevinSR import mask_interpolation, SOUP_GAN\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from scipy import ndimage, interpolate\n",
    "# from scipy.ndimage import zoom\n",
    "# from KevinSR import SOUP_GAN\n",
    "# import monai\n",
    "\n",
    "# import SimpleITK as sitk\n",
    "\n",
    "# path = df['t2w'].to_numpy()[0]\n",
    "\n",
    "\n",
    "\n",
    "# spacingX_a= 0.234375\n",
    "# spacingX_b= 0.78125\n",
    "\n",
    "# spacingY_a= 0.234375\n",
    "# spacingY_b= 0.78125\n",
    "\n",
    "# spacingZ_a= 2.200000060372773\n",
    "# spacingZ_b= 5.000000066297424\n",
    "\n",
    "# img = sitk.ReadImage(path)\n",
    "# image1 = sitk.ReadImage(path)\n",
    "\n",
    "# thicks_ori = sitk.GetArrayFromImage(image1)\n",
    "# Z_FAC = spacingZ_b/spacingZ_a\n",
    "\n",
    "# # Call the SR interpolation tool from KevinSR\n",
    "# thins_gen = SOUP_GAN(thicks_ori, Z_FAC, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #recreating image keeping relevant metadata\n",
    "# image = sitk.GetImageFromArray(data)\n",
    "# image.SetSpacing(image1.GetSpacing())\n",
    "# image.SetOrigin(image1.GetOrigin())\n",
    "# image.SetDirection(image1.GetDirection())\n",
    "\n",
    "\n",
    "\n",
    "# #Example of thick-to-thin type of preprocessing\n",
    "# pre_slices = 27\n",
    "# post_slices = 135\n",
    "\n",
    "\n",
    "# # thicks_ori = load_data(DIR_dicom)\n",
    "# # Z_FAC = post_slices/pre_slices # Sampling factor in Z direction\n",
    "\n",
    "# # thicks_ori = rescale_img(thicks_ori, max_val= 10000)\n",
    "\n",
    "# # thins = zoom(thicks_ori, (1,1,Z_FAC))\n",
    "# # thins_raw = zoom(thicks_ori, (1,1,Z_FAC),order=0)\n",
    "\n",
    "# # # Call the SR interpolation tool from KevinSR\n",
    "# # thins_gen = SOUP_GAN(thicks_ori, Z_FAC, 0)\n",
    "\n",
    "# # # Plot the original thick slices, thin slices by TCI and SR generated slices. \n",
    "# # plot_scans(thins_raw, thins, thins_gen, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for keyWord in ['t2w','adc', 'cor','hbv','sag'  ]: \n",
    "#     for addedKey in ['_sizz_x','_sizz_y','_sizz_z','_spac_x'\n",
    "#                         ,'_spac_y','_spac_z'\n",
    "#                         ,'_orig_x','_orig_x','_orig_x']:  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
